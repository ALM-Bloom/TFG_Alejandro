{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05bba68d",
   "metadata": {},
   "source": [
    "### Carga del modelo especializado desde HuggingFace\n",
    "\n",
    "El siguiente bloque de código realiza la correspondiente carga del modelo previamente especializado y almacenado en HuggingFace.\n",
    "También se carga el tokenizador correspondiente al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba6582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "new_model = \"DrAleML/Oswestry-Instruct\"\n",
    "base_model_reload = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        return_dict=True,\n",
    "      low_cpu_mem_usage=True,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model_reload, new_model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"DrAleML/Oswestry-Instruct\")\n",
    "modelo_path = \"DrAleML/Oswestry-Instruct\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a132d07",
   "metadata": {},
   "source": [
    "### Script de Precisión basada en el conjunto invidual de ítems\n",
    "\n",
    "Primero, se configura un pipeline de generación de texto que, dado un prompt de entrada (la entrevista), genera una respuesta del modelo. La respuesta generada es analizada mediante una función de extracción que utiliza expresiones regulares para identificar las puntuaciones asignadas a cada uno de los 10 ítems esperados de la escala (como \"Intensidad dolor\", \"Andar\", \"Dormir\", etc.).\n",
    "\n",
    "A continuación, se evalúa el desempeño del modelo sobre un conjunto de datos de prueba (`test_set`). Para cada muestra, se construye un prompt con formato específico, se obtiene la salida generada por el modelo, y se comparan las puntuaciones extraídas con las puntuaciones reales esperadas. Las diferencias absolutas entre valores reales y predichos se registran para cada ítem.\n",
    "\n",
    "Finalmente, se calcula y se imprime la media y la desviación estándar del error para cada uno de los ítems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319ccf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=1024,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "NOMBRES_ESPERADOS = [\n",
    "    \"Intensidad dolor\", \"Estar pie\", \"Andar\", \"Cuidados personales\", \"Levantar peso\",\n",
    "    \"Estar sentado\", \"Viajar\", \"Vida social\", \"Actividad sexual\", \"Dormir\"\n",
    "]\n",
    "\n",
    "def extraer_items(texto):\n",
    "    resultados = {}\n",
    "    for nombre in NOMBRES_ESPERADOS:\n",
    "        patron = re.search(rf\"{nombre}.*?:\\s*(\\d+)\\s*puntos?\", texto, re.IGNORECASE)\n",
    "        resultados[nombre] = int(patron.group(1)) if patron else -1\n",
    "    return resultados\n",
    "\n",
    "# Dataset de prueba \n",
    "test_set = [ # Aquí se establece el conjunto de datos de prueba\n",
    "]\n",
    "\n",
    "\n",
    "errores_por_item = {nombre: [] for nombre in NOMBRES_ESPERADOS}\n",
    "\n",
    "for idx, muestra in enumerate(tqdm(test_set)):\n",
    "    \n",
    "    prompt = f\"\"\"<s>[INST] Clasifica la siguiente entrevista médico-paciente según la Escala Oswestry de discapacidad lumbar.\\n\\n{muestra['input']} [/INST]\"\"\"\n",
    "    salida = pipe(prompt)[0]['generated_text']\n",
    "    pred = extraer_items(salida)\n",
    "    esperado = muestra['esperado']\n",
    "\n",
    "    print(f\"\\n Entrevista {idx+1}\")\n",
    "    print(\"Respuesta generada:\")\n",
    "    print(salida)\n",
    "    print(\"Diferencias por ítem:\")\n",
    "\n",
    "    for item in NOMBRES_ESPERADOS:\n",
    "        real = esperado.get(item, -1)\n",
    "        modelo = pred.get(item, -1)\n",
    "        if real != -1 and modelo != -1:\n",
    "            error = abs(real - modelo)\n",
    "            errores_por_item[item].append(error)\n",
    "            print(f\" - {item:<20} | Esperado: {real} | Modelo: {modelo} | Diferencia: {error}\")\n",
    "\n",
    "# Resultados por ítem\n",
    "print(\"\\nEvaluación por ítem (promedio y desviación estándar de error)\")\n",
    "for item in NOMBRES_ESPERADOS:\n",
    "    errores = errores_por_item[item]\n",
    "    if errores:\n",
    "        media = np.mean(errores)\n",
    "        std = np.std(errores)\n",
    "        print(f\" - {item:<20} | Media error: {media:.2f} | Desviación estándar: {std:.2f}\")\n",
    "    else:\n",
    "        print(f\" - {item:<20} | Sin datos suficientes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0356af",
   "metadata": {},
   "source": [
    "### Script de Precisión basada en la puntuación total por entrevista\n",
    "\n",
    "Este script se centra en el cálculo del error total por entrevista.\n",
    "\n",
    "Se utiliza un pipeline de generación de texto (`transformers`) previamente configurado, que toma como entrada una transcripción de entrevista y genera una clasificación automática en forma de texto. A partir de esa salida generada, se extraen las puntuaciones correspondientes a los 10 ítems de la escala Oswestry usando expresiones regulares.\n",
    "\n",
    "Para cada muestra del conjunto de prueba (`test_set`), se construye un prompt en lenguaje natural que se pasa al modelo. Luego se comparan las puntuaciones generadas con las puntuaciones reales esperadas. En este caso, en lugar de evaluar ítem por ítem, se calcula la **suma total** de las puntuaciones reales y generadas por el modelo, y se registra el error absoluto entre ambas.\n",
    "\n",
    "Al final, se imprime la **media** y la **desviación estándar** del error total por entrevista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e24e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=1024,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "NOMBRES_ESPERADOS = [\n",
    "    \"Intensidad dolor\", \"Estar pie\", \"Andar\", \"Cuidados personales\", \"Levantar peso\",\n",
    "    \"Estar sentado\", \"Viajar\", \"Vida social\", \"Actividad sexual\", \"Dormir\"\n",
    "]\n",
    "\n",
    "def extraer_items(texto):\n",
    "    resultados = {}\n",
    "    for nombre in NOMBRES_ESPERADOS:\n",
    "        patron = re.search(rf\"{nombre}.*?:\\s*(\\d+)\\s*puntos?\", texto, re.IGNORECASE)\n",
    "        resultados[nombre] = int(patron.group(1)) if patron else -1\n",
    "    return resultados\n",
    "\n",
    "# Dataset de prueba \n",
    "test_set = [ # Aquí se establece el conjunto de datos de prueba\n",
    "]\n",
    "\n",
    "errores = []\n",
    "\n",
    "#Evaluación por entrevista completa\n",
    "\n",
    "errores_por_entrevista = []\n",
    "\n",
    "for idx, muestra in enumerate(tqdm(test_set)):\n",
    "    prompt = f\"\"\"<s>[INST] Clasifica la siguiente entrevista médico-paciente según la Escala Oswestry de discapacidad lumbar.\\n\\n{muestra['input']} [/INST]\"\"\"\n",
    "    salida = pipe(prompt)[0]['generated_text']\n",
    "    pred = extraer_items(salida)\n",
    "    esperado = muestra['esperado']\n",
    "\n",
    "    total_real = sum(esperado.get(k, 0) for k in NOMBRES_ESPERADOS)\n",
    "    total_modelo = sum(pred.get(k, 0) if pred.get(k, 0) != -1 else 0 for k in NOMBRES_ESPERADOS)\n",
    "    error_total = abs(total_real - total_modelo)\n",
    "    errores_por_entrevista.append(error_total)\n",
    "\n",
    "    print(f\"\\nEntrevista {idx+1}\")\n",
    "    print(\"Respuesta generada:\")\n",
    "    print(salida)\n",
    "    print(f\"Puntuación esperada: {total_real} | Modelo: {total_modelo} | Diferencia: {error_total}\")\n",
    "\n",
    "print(\"\\nEvaluación por entrevista completa\")\n",
    "print(f\"Media de error total por entrevista: {np.mean(errores_por_entrevista):.2f} puntos\")\n",
    "print(f\"Desviación estándar del error total: {np.std(errores_por_entrevista):.2f} puntos\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
